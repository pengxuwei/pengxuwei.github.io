<!DOCTYPE html>
<html lang="en">
<head>
    <title>Pengxu Wei</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Boootstrap Portfolio/Resume Theme for Developers">
    <meta name="author" content="Xiaoying Riley at 3rd Wave Media">    
    <link rel="shortcut icon" href="wei.ico">
    
    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'> 
    
    <!-- FontAwesome JS -->
    <script defer src="assets/fontawesome/js/all.js"></script>
    
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    
    <!-- github calendar css -->
    <link rel="stylesheet" href="assets/plugins/github-calendar/dist/github-calendar.css">
    <!-- github activity css -->    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/octicons/2.0.2/octicons.min.css">
    <link rel="stylesheet" href="assets/plugins/github-activity/github-activity-0.1.5.min.css">
    
    <!-- Theme CSS -->  
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
    
</head> 

<body>
    <!-- ******HEADER****** --> 
    <header class="header">
        <div class="container clearfix">                       
            <img class="profile-image img-fluid float-left rounded-circle" src="assets/images/pengxu02-.png" alt="profile image" />
            <div class="profile-content float-left">
                <h1 class="name">Pengxu Wei (魏朋旭)</h1>
                <h2 class="desc">HCP Lab, Sun Yat-sen University</h2>
                <ul class="social list-inline">
<!--                    <li class="list-inline-item"><a href="#"><i class="fab fa-twitter"></i></a></li>-->
                    <li class="list-inline-item"><a href="https://scholar.google.com/citations?user=ZsScBwMAAAAJ&hl=en"  target="_blank"><i class="fa fa-graduation-cap"></i></a></li>
                </ul> 
            </div><!--//profile-->
<!--            <a class="btn btn-cta-primary float-right" href="weipx3@mail.sysu.edu.cn" target="_blank"><i class="content"></i> Email Me</a>-->
        </div><!--//container-->
    </header><!--//header-->
    
    <div class="container sections-wrapper">
        <div class="row">
            <div class="primary col-lg-8 col-12">
                <section class="about section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">About Me</h2>
                        <div class="content">
                            <p>I am a <b>research scientist</b> at the at the School of Computer Science and Engineering, <b>Sun Yat-sen University (SYSU)</b>,
                            where I work in <a href = "https://www.sysu-hcp.net/" target="_blank">HCP Lab</a> (Human-Cyber-Physical Intelligence Integration Lab) supervised by <a href = "http://www.linliang.net/" target="_blank">Prof. Liang Lin</a>.
                            Before that, I received the Ph.D in Computer Science from University of the Chinese Academy of Sciences in 2018, advised by <a href = "http://people.ucas.ac.cn/~0004776?language=en" target="_blank"> Prof. Jianbin Jiao</a> and <a href = "http://people.ucas.ac.cn/~qxye?language=en" target="_blank"> Prof. Qixiang Ye</a>. I obtained the B.Eng.
                            from China University of Mining and Technology, Beijing, advised by Prof. Feng Yang.</p>

                            <p><b>Research interest: </b> My general research interest is <b>Towards Transferable, Robust and Reliable Model Learning</b> for computer vision tasks.
                            Recently, I specifically focus on 
                            <li>  <b>1) high-level vision: </b>weakly-supervised object detection, unsupervised domain adaptation, robust object detection, adversarial attack and defense;</li> 
                            <li>  <b>2) low-level vision: </b>real-world image Super-Resolution (e.g., real-world SR benchmarks, single image real-world SR, unsupervised domain adaptation real-world SR, robust real-world SR).</li> </p>

                        </div><!--//content-->
                    </div><!--//section-inner-->                 
                </section><!--//section-->


                <section class="projects section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">News</h2>
                        <div class="content">
                            <ul style="list-style: outside;">

                            <li>  <b>[Jun 2023] </b> Two papers are accepted for ICCV 2023. </li>
                                
                            <li>  <b>[Mar 2023] </b> Three papers are accepted for CVPR 2023. </li>
                            
                            <li>  <b>[Feb 2023] </b> One paper on real-world SR is accepted for TIP 2023.</li>
                            
                            <li>  <b>[Feb 2023] </b> One paper on scene graph to image synthesis is accepted for AAAI 2023.</li>
                                
                            <li>  <b>[Jul 2022] </b> One paper on adversarially-robust object detector is accepted as ECCV 2022 <b>oral</b> paper (2.7% of submitted papers). [<a href = "https://github.com/7eu7d7/RobustDet" target="_blank" >Project</a>]</li>

                            <li>  <b>[Mar 2022] </b> One paper on real-world SR is accepted as CVPR 2022 <b>oral</b> paper (4.2% of submitted papers). [<a href = "https://github.com/lonelyhope/DADA.git" target="_blank" >Project</a>]</li>

                            <li>  <b>[Aug 2021] </b> IEEE CASS Seasonal School on New Trends of Visual and Language Understanding was held online on August 20-22, 2021.</li>

                            <li>  <b>[Aug 2020] </b> AIM 2020 Real Image Super-Resolution Challenge starts on May 8, 2020 and ends on July 17, 2021. Congratulations to the Challenge Winners! [<a href = "https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank" >Awards</a>]</li>

                            <li>  <b>[Aug 2020] </b> A large-scale diverse real-world image super-resolution dataset, DRealSR, is released. [<a href = "https://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution" target="_blank" >Link</a>]</li>

                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->




               <section class="latest section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Selected Publications</h2>
<!--                         <li>  <b>Real-World Image Super-Resolution</li>-->
                        <div class="content">

<!--                            <hr class="divider" />-->
<!--                           Low-Level Vision />-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/ICCV2023-RealBSR/RealBSR.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Towards Real-World Burst Image Super-Resolution: Benchmark and Method
                                    </h3>
                                    <p class="mb-2"><b>Pengxu Wei</b>, Yujing Sun, Xingbei Guo, Chang Liu, Guanbin Li, Jie Chen, Xiangyang Ji, Liang Lin</p>
                                    <p class="mb-2">ICCV 2023 [<a href = "" target="_blank" >Project</a>,
                                        <a href = "" target="_blank" >Dataset&Code</a>,
                                        <a href = "" target="_blank">Paper</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->
                            
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/CVPR2023-RobustFinetuning/CVPR2023-RobustFinetuning.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Masked Images Are Counterfactual Samples for Robust Fine-tuning
                                    </h3>
                                    <p class="mb-2">Yao Xiao, Ziyi Tang, <b>Pengxu Wei*</b>, Cong Liu, Liang Lin</p>
                                    <p class="mb-2">CVPR 2023 [<a href = "https://github.com/Coxy7/robust-finetuning" target="_blank" >Project</a>,
                                        <a href = "https://github.com/Coxy7/robust-finetuning" target="_blank" >Code</a>,
                                        <a href = "assets/files/CVPR2023-RobustFinetuning/CVPR2023-RobustFinetuning.pdf" target="_blank">Paper</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->
                            
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2023TIP-TNN/TNN.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Taylor Neural Network for Real-World Image Super-Resolution
                                    </h3>
                                    <p class="mb-2"><b>Pengxu Wei</b>, Ziwei Xie, Guanbin Li, Liang Lin*</p>
                                    <p class="mb-2">TIP 2023 [<a href = "" target="_blank" >Code (coming soon)</a>,
                                        <a href = "assets/files/2023TIP-TNN/TNN.pdf" target="_blank">Paper</a>]                                        
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->
                            
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2023AAAI-SceneGraph/2023AAAI-SceneGraph.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Scene Graph to Image Synthesis via Knowledge Consensus
                                    </h3>
                                    <p class="mb-2">Yang Wu, <b>Pengxu Wei*</b>, Liang Lin</p>
                                    <p class="mb-2">AAAI 2023 [<a href = "" target="_blank" >Code (coming soon)</a>,
                                        <a href = "assets/files/2023AAAI-SceneGraph/2023AAAI-SceneGraph.pdf" target="_blank">Paper</a>]                                        
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->
                            
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2022ECCV-RobustDet/RobustDet.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Adversarially-Aware Robust Object Detector
                                    </h3>
                                    <p class="mb-2">Ziyi Dong, <b>Pengxu Wei*</b>, Liang Lin</p>
                                    <p class="mb-2">ECCV 2022 (oral) [<a href = "https://github.com/7eu7d7/RobustDet" target="_blank" >Project</a>,
                                        <a href = "https://github.com/7eu7d7/RobustDet" target="_blank" >Code</a>,
                                        <a href = "assets/files/2022ECCV-RobustDet/2022ECCV-RobustDet.pdf" target="_blank">Paper</a>
                                        <a href = "assets/files/2022ECCV-RobustDet/2022ECCV-RobustDet-supp.pdf" target="_blank">Supplementary</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->
                            
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2022dada/DADA.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution
                                    </h3>
                                    <p class="mb-2">Xiaoqian Xu, <b>Pengxu Wei*</b>, Weikai Chen, Yang Liu, Liang Lin and Guanbin Li</p>
                                    <p class="mb-2">CVPR 2022 (oral)  [<a href = "https://github.com/lonelyhope/DADA.git" target="_blank" >Project</a>,
                                        <a href = "https://github.com/lonelyhope/DADA.git" target="_blank" >Code</a>,
                                        <a href = "assets/files/2022dada/DADA.pdf" target="_blank">Paper</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->
                            
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2022ICME-Action/2022ICME-Action.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Cross-Domain Action Recognition via Prototypical Graph Alignment
                                    </h3>
                                    <p class="mb-2">Binbin Yang, Junhao Zhong, <b>Pengxu Wei*</b>, Dongyu Zhang and Liang Lin</p>
                                    <p class="mb-2">ICME 2022 (oral)  [<a href = "assets/files/2022ICME-Action/ICME2022_PGA.pdf" target="_blank">Paper</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021mm/MM2021-figure.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Robust Real-World Image Super-Resolution against Adversarial Attacks
                                    </h3>
                                    <p class="mb-2">Jiutao Yue, Haofeng Li, <b>Pengxu Wei*</b>, Guanbin Li and Liang Lin</p>
                                    <p class="mb-2">ACM Multimedia, 2021. [<a href = "assets/files/2021mm/MM2021.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021mm/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2020cdc/CDC.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Component Divide-and-Conquer for Real-World Image Super-Resolution</h3>
                                    <p class="mb-2"><b>Pengxu Wei</b>, Ziwei Xie, Hannan Lu, Zongyuan Zhan, Qixiang Ye, Wangmeng Zuo and Liang Lin</p>
                                    <p class="mb-2">ECCV, 2020. [<a href = "assets/files/2020cdc/Wei2020_CDC.pdf" target="_blank">Paper</a>,
                                        <a href = "https://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution" target="_blank" >Project</a>,
                                        <a href = "https://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution" target="_blank" >Code</a>,
                                        <a href = "assets/files/2020cdc/bibtex.txt" target="_blank" >BibTex</a>]
                                    <!--<a href="assets/files/autoeval/Slides_CVPR_2021_AutoEvaluation.pdf" target="_blank">Slides</a>] -->
                                    </p>
<!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2020aim/AIM2020.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">AIM 2020 Challenge on Real Image Super-Resolution: Methods and Results
                                    </h3>
                                    <p class="mb-2"><b>Pengxu Wei*</b>, Hannan Lu, Radu Timofte, Liang Lin, Wangmeng Zuo, et al.</p>
                                    <p class="mb-2">ECCV workshop, 2020. [<a href = "assets/files/2020aim/Wei2020_Chapter_AIM2020ChallengeOnRealImageSup.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2020aim/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->


<!--                           High-Level Vision />-->
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021ijcv/IJCV2021.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Deep CockTail Networks: A Universal Framework for Visual Multi-source Domain Adaptation</h3>
                                    <p class="mb-2">Ziliang Chen, <b>Pengxu Wei*</b>, Jingyu Zhuang, Guanbin Li and Liang Lin</p>
                                    <p class="mb-2">IJCV, 2021. [<a href = "assets/files/2021ijcv/IJCV2021.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021ijcv/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021tnnls/figure.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Deductive Reinforcement Learning for Visual Autonomous Urban Driving Navigation
                                    </h3>
                                    <p class="mb-2">Changxin Huang, Ronghui Zhang, Meizi Ouyang, <b>Pengxu Wei*</b>, Junfan Lin, Jiang Su and Liang Lin</p>
                                    <p class="mb-2">IEEE TNNLS, 2021. [<a href = "assets/files/2021tnnls/Deductive_Reinforcement_Learning_for_Visual_Autonomous_Urban_Driving_Navigation.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021tnnls/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12" >
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021aaai/AAAI2021-figure.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras</h3>
                                    <p class="mb-2">Xipeng Chen, <b>Pengxu Wei*</b> and Liang Lin</p>
                                    <p class="mb-2">AAAI, 2021. [<a href = "assets/files/2021aaai/AAAI2021.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021aaai/bibtex.txt" target="_blank" >BibTex</a>]</p>
<!--                                    <p class="mb-2">(Journal version of <a href = "https://arxiv.org/abs/1812.00893" target="_blank">"Domain alignment with triplets"</a>)</p>-->
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2019pami/pami2019.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Min-Entropy Latent Model for Weakly Supervised Object Detection</h3>
                                    <p class="mb-2">Fang Wan, <b>Pengxu Wei</b>, Zhenjun Han, Jianbin Jiao and Qixiang Ye</p>
                                    <p class="mb-2">CVPR 2018 [<a href = "[CVPR]Min-Entropy Latent Model for Weakly Supervised Object Detection.pdf" target="_blank">Paper</a>]; IEEE T-PAMI, 2019 [<a href = "assets/files/2019pami/[2019PAMI]Min-Entropy Latent Model for Weakly Supervised Object Detection.pdf" target="_blank">Paper</a>,
                                        <a href = "https://github.com/WinFrand/MELM" target="_blank">Project&Code</a>]</p>
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2020pose/figure.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">3D Human Pose Machines with Self-Supervised Learning</h3>
                                    <p class="mb-2">Keze Wang, Liang Lin, Chenhan Jiang, Chen Qian, <b>Pengxu Wei</b></p>
                                    <p class="mb-2">IEEE T-PAMI 2020 [<a href = "https://ieeexplore.ieee.org/document/8611195" target="_blank">Paper</a>]
                                        <a href = "assets/files/2020pose/bibtex.txt" target="_blank">BibTex</a>]</p>
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->


<!--                           Others />-->
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021tnnls/figure.jpg" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Graph-Convolved Factorization Machines for Personalized Recommendation
                                    </h3>
                                    <p class="mb-2">Yongsen Zheng, <b>Pengxu Wei*</b>, Ziliang Chen, Yang Cao and Liang Lin</p>
                                    <p class="mb-2">IEEE Transactions on Knowledge and Data Engineering (TKDE), 2021. [<a href = "assets/files/2021tkde/Graph-Convolved_Factorization_Machines_for_Personalized_Recommendation.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021tnnls/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->



                        </div><!--//content-->  
                    </div><!--//section-inner-->                
                </section><!--//section-->

                <section class="projects section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Selected Projects</h2>
                        <div class="content">

                            <div class="item">
                                <h3 class="title">A Near-Optimal Generative Learning Scheme for Neural Energy-Based Models</h3>
                                <p class="summary">Yang Wu, Xu cai, <b>Pengxu Wei</b>, Liang Lin.
                                </p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title">Real-World Image Super-Resolution Challenge (AIM 2020 in conjunction with ECCV 2020) [<a href = "https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank">AIM2020 webpage</a>]</h3>
                                <p class="summary">We provide high/low resolution image pairs of 3 scales captured by 5 different DSLR cameras through zooming lens. The challenging contains 3 tracks, one track per scale. The detail of the dataset is provided in Table 1. For the convergence of training, images in the trainset are cropped into fixed size patches using sliding window after careful alignment for image pairs. [<a href = "https://competitions.codalab.org/competitions/24680" target="_blank">Chanllenge Page</a>] </p>
                                <p>
                                    <b>Organizers</b>: Pengxu Wei (Sun Yat-Sen University), Hannan Lu (Harbin Institute of Technology), Wangmeng Zuo (Harbin Institute of Technology), Radu Timofte (ETH Zurich)
                                </p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title">IEEE CASS Seasonal School on New Trends of Visual and Language Understanding (NT-VLU) [<a href = "http://ieeecass.sysuhcp.com/" target="_blank">Website</a>, <a href = "https://live.bilibili.com/23453433" target="_blank">Video</a>]</h3>
                                <p class="summary">To organize the IEEE CASS Seasonal School on NT-VLU, we invited several top-tier researchers to present their works and arrange two panels to discuss the new trends of NT-VLU. This seasonal school aimed to promote the frontier of language and vision research and to provide an ambiance for fruitful exchange of ideas and discussion of advances, challenges, and trends of this area in the near future. [<a href = "http://ieeecass.sysuhcp.com/" target="_blank">Website</a>] </p>
                                <p>
                                    <b>Spearkers</b>: Jiebo Luo (University of Rochester), Cees G.M. Snoek (University of Amsterdam), Wen-Huang Cheng (National Yang Ming Chiao Tung University), Hanwang Zhang (Nanyang Technological University), Michael Kampffmeyer (UiT the Arctic University of Norway), Dan Xu (Hong Kong University of Sciences and Technology), Pengfei Liu (Carnegie Mellon University)
                                </p>
                                <p>
                                    <b>Organizers</b>: Liang Lin(Sun Yat-Sen University), Wangmeng Zuo (Harbin Institute of Technology), Xiaodan Liang(Sun Yat-Sen University), Yunchao Wei (Beijing Jiaotong University), Pengxu Wei (Sun Yat-Sen University), Guanbin Li(Sun Yat-Sen University)
                                </p>
                            </div><!--//item-->

                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->


            </div><!--//primary-->


            <div class="secondary col-lg-4 col-12">
                 <aside class="info aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading sr-only">Basic Information</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li><i class="fas fa-map-marker-alt"></i><span class="sr-only">Location:</span>Guangzhou, China</li>
<!--                                <li><i class="fas fa-file"></i><span class="sr-only">Curriculum Vitae:</span><a href="assets/files/CV.pdf" target="_blank">Curriculum Vitae</a></li> -->
                                <li><i class="fas fa-envelope"></i><span class="sr-only">Email:</span><a href="#">weipx3@mail.sysu.edu.cn</a></li>

                            </ul>
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//aside-->

                
                <aside class="testimonials aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Recent Focus</h2>
                        <div class="content">
                            <div class="item">
                                <blockquote class="quote">                                  
                                    <p><i class="fas fa-quote-left"></i> Towards Transferable, Robust and Reliable Model Learning</p>
                                </blockquote>                
                            </div><!--//item-->
                            
                            
<!--                             <p><a class="more-link" href="https://github.io/"target="_blank"><i class="fas fa-external-link-alt"></i>Our recent work</a></p>-->
                            
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->




                <aside class="credits aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Professional Service</h2>
                        <div class="content">
                            <ul class="list-unstyled pb-2">
                                <li><b>Reviewer</b>: CVPR; ICCV; ECCV; ICLR; IJCAI; AAAI; IEEE-TPAMI; IEEE-TIP; IEEE-TCSVT, CVIU</li>
                                <li><b>Co-organizer</b>: IEEE CASS Seasonal School 2021 on <a href = "http://ieeecass.sysuhcp.com/" target="_blank">"New Trends of Visual and Language Understanding"</a>; ECCV 2020 workshop on <a href = "http://ai.bu.edu/visda-2020" target="_blank"> AIM 2020 "Real-World Image Super-Resolution Challenge"</a></li>
<!--                                <li><b>Guest speaker</b>:  </li> -->
                                <li> </li>
                            </ul>

                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->


                <script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=5x16sh9ozi2&amp;m=7&amp;c=baff00&amp;cr1=ff0000&amp;sx=0" async="async"></script>

              
            </div><!--//secondary-->    
        </div><!--//row-->
    </div><!--//masonry-->
    
    <!-- ******FOOTER****** --> 
    <footer class="footer">
        <div class="container text-center">
                <!--/* This template is free as long as you keep the attribution link below. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
                <small class="copyright">Designed with <i class="fas fa-heart"></i> by <a href="https://themes.3rdwavemedia.com" target="_blank">Xiaoying Riley</a> for developers</small>
        </div><!--//container-->
    </footer><!--//footer-->
 
    <!-- Javascript -->          
    <script type="text/javascript" src="assets/plugins/jquery-3.4.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/popper.min.js"></script> 
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>    
    <script type="text/javascript" src="assets/plugins/jquery-rss/dist/jquery.rss.min.js"></script> 
    <!-- github calendar plugin -->
    <script type="text/javascript" src="assets/plugins/github-calendar/dist/github-calendar.min.js"></script>
    <!-- github activity plugin -->
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mustache.js/0.7.2/mustache.min.js"></script>
    <script type="text/javascript" src="assets/plugins/github-activity/github-activity-0.1.5.min.js"></script>
    <!-- custom js -->
    <script type="text/javascript" src="assets/js/main.js"></script>            
</body>
</html> 

