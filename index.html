<!DOCTYPE html>
<html lang="en">
<head>
    <title>Pengxu Wei</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Boootstrap Portfolio/Resume Theme for Developers">
    <meta name="author" content="Xiaoying Riley at 3rd Wave Media">    
    <link rel="shortcut icon" href="favicon.ico">
    
    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'> 
    
    <!-- FontAwesome JS -->
    <script defer src="assets/fontawesome/js/all.js"></script>
    
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    
    <!-- github calendar css -->
    <link rel="stylesheet" href="assets/plugins/github-calendar/dist/github-calendar.css">
    <!-- github activity css -->    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/octicons/2.0.2/octicons.min.css">
    <link rel="stylesheet" href="assets/plugins/github-activity/github-activity-0.1.5.min.css">
    
    <!-- Theme CSS -->  
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
    
</head> 

<body>
    <!-- ******HEADER****** --> 
    <header class="header">
        <div class="container clearfix">                       
            <img class="profile-image img-fluid float-left rounded-circle" src="assets/images/pengxu.png" alt="profile image" />
            <div class="profile-content float-left">
                <h1 class="name">Pengxu Wei</h1>
                <h2 class="desc">research scientist</h2>
                <ul class="social list-inline">
<!--                    <li class="list-inline-item"><a href="#"><i class="fab fa-twitter"></i></a></li>-->
                    <li class="list-inline-item"><a href="https://scholar.google.com/citations?user=ZsScBwMAAAAJ&hl=en"  target="_blank"><i class="fa fa-graduation-cap"></i></a></li>
<!--                    <li class="list-inline-item"><a href="http://github.com/Simon4Yan"  target="_blank"><i class="fab fa-github"></i></a></li>
<!--                    <li class="list-inline-item"><a href="assets/files/DENG-WEIJIAN-CV.pdf"  target="_blank"><i class="fas fa-file"></i></a></li>
<!--                    <li class="list-inline-item"><a href="https://www.zhihu.com/people/simon-john-9" target="_blank"><i class="fab fa-zhihu"></i></a></li>-->
<!--                    <li class="list-inline-item last-item"><a href="#"><i class="fab fa-codepen"></i></a></li>                -->
                </ul> 
            </div><!--//profile-->
<!--            <a class="btn btn-cta-primary float-right" href="weijian.deng@anu.edu.au" target="_blank"><i class="content"></i> Email Me</a>-->
        </div><!--//container-->
    </header><!--//header-->
    
    <div class="container sections-wrapper">
        <div class="row">
            <div class="primary col-lg-8 col-12">
                <section class="about section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">About Me</h2>
                        <div class="content">
                            <p>I am a <b>research scientist</b> at the at the School of Computer Science and Engineering, <b>Sun Yat-sen University (SYSU)</b>,
                            where I work in <a href = "https://www.sysu-hcp.net/" target="_blank">HCP Lab</a> (Human-Cyber-Physical Intelligence Integration Lab) supervised by <a href = "http://www.linliang.net/" target="_blank">Prof. Liang Lin</a>.
                            Before that, I received the Ph.D in Computer Science from University of the Chinese Academy of Sciences in 2018, advised by <a href = "http://people.ucas.ac.cn/~0004776?language=en" target="_blank"> Prof. Jianbin Jiao</a> and <a href = "http://people.ucas.ac.cn/~qxye?language=en" target="_blank"> Prof. Qixiang Ye</a>. I obtained the B.Eng.
                            from China University of Mining and Technology, Beijing, advised by Prof. Feng Yang.</p>

                            <p><b>Research interest: </b> My general research interest is Towards Transferable, Robust and Reliable Model Learning for computer vision tasks.
                            Recently, I specifically focus on <b>1) high-level vision: </b>weakly-supervised object detection, unsupervised domain adaptation, robust object detection, adversarial attack and defense;
                            <b>1) low-level vision: </b>real-world image Super-Resolution (e.g., real-world SR benchmarks, single image real-world SR, unsupervised domain adaptation real-world SR, robust real-world SR).</p>

                        </div><!--//content-->
                    </div><!--//section-inner-->                 
                </section><!--//section-->


                <section class="projects section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">News</h2>
                        <div class="content">
                            <ul style="list-style: outside;">

                            <li>  <b>[Mar 2022] </b> One paper on real-world SR is accepted to the oral paper of CVPR 2022. [<a href = "https://github.com/lonelyhope/DADA.git" target="_blank" >Project</a>]</li>

                            <li>  <b>[Aug 2021] </b> IEEE CASS Seasonal School on New Trends of Visual and Language Understanding was held online on August 20-22, 2021.</li>

                            <li>  <b>[Aug 2020] </b> AIM 2020 Real Image Super-Resolution Challenge starts on May 8, 2020 and ends on July 17, 2021. Congratulations to the Challenge Winners! [<a href = "https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank" >Awards</a>]</li>

                            <li>  <b>[Aug 2020] </b> A large-scale diverse real-world image super-resolution dataset, DRealSR, is released. [<a href = "https://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution" target="_blank" >Link</a>]</li>

                                <!--                            <li>  <b>[May 2021] </b> One paper is accepted to ICML, 2021. [<a href = "assets/files/icml/ICML'21.pdf" target="_blank">Paper</a>,
                                <a href = "https://simon4yan.github.io/Rotation/" target="_blank" >Project</a>]</li>
                            <li>  <b>[Mar 2021] </b> One paper is accepted to CVPR, 2021. [<a href = "assets/files/autoeval/AUTOEVAL_CVPR_2021.pdf" target="_blank">Paper</a>,
                            <a href = "https://simon4yan.github.io/AutoEval/" target="_blank" >Project</a>]</li>

                            <li>  <b>[Jul 2020 - Sep 2020]</b> Summer intern in NEC Labs America. Wonderful experience with my talented mentors Yumin Suh, Xiang Yu, Masoud Faraki, and Manmohan Chandraker.</li>

                            <li>  <b>[Aug 2020]</b> VisDA-2020 challenge successfully ends. Congratulations to the [<a href = "https://github.com/Simon4Yan/VisDA2020_Code_From_Top_Teams/" target="_blank">final teams</a>]!</li>
                            Big thanks to all committee members Kate Saenko, Liang Zheng, and Xingchao Peng!

                            <li>  <b>[Jan 2020]</b> One paper is accepted to IEEE TCSVT. [<a href = "https://ieeexplore.ieee.org/abstract/document/8964455/" target="_blank">Paper</a>]</li>

                            <li>  <b>[Jul 2020]</b> Honoured to be recognized by ECCV2020 as a top reviewer. [<a href = "https://eccv2020.eu/outstanding-reviewers/" target="_blank">Link</a>]</li>

                            <li>  <b>[Jul 2019]</b> Study PhD program at The Australian National University. My reseach is supported by Australian Governmen Scholarship [<a href = "https://www.anu.edu.au/study/scholarships/find-a-scholarship/australian-government-research-training-program-agrtp" target="_blank">AGRTP</a>].</li>

                            <li>  <b>[Jun 2019]</b> Receive M.Eng. from the University of the Chinese Academy of Sciences.</li>

                            <li>  <b>[Jun 2019]</b> Win 3rd place out of 84 participants in vehicle re-identification in CVPR 2019 AI-City Challenge.</li>
                            [<a href = "http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Lv_Vehicle_Re-Identification_with_Location_and_Time_Stamps_CVPRW_2019_paper.pdf" target="_blank">Paper</a>,
                            <a href = "https://github.com/Simon4Yan/feature_learning" target="_blank">Code</a>]</li>


                            <li>  <b>[Jul 2018 - Nov 2018]</b> Reserch assistant in Singapore University of Technology and Design (SUTD).</li>

                            <li>  <b>[Mar 2018]</b> One paper is accepted to CVPR, 2018. [<a href = "http://openaccess.thecvf.com/content_cvpr_2018/html/Deng_Image-Image_Domain_Adaptation_CVPR_2018_paper.html" target="_blank">Paper</a>,
                            <a href = "https://github.com/Simon4Yan/Learning-via-Translation" target="_blank" >Code</a>]</li>

                            <li>  <b>[Jul 2017]</b> One paper is accepted to ICCV, 2017. [<a href = "http://openaccess.thecvf.com/content_iccv_2017/html/Sun_SVDNet_for_Pedestrian_ICCV_2017_paper.html" target="_blank">Paper</a>,
                            <a href = "https://github.com/Simon4Yan/SVDNet-for-Pedestrian-Retrieval" target="_blank">Code</a>]</li>
                            </ul>
-->
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->




               <section class="latest section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Selected Publications</h2>
                        <div class="content">

<!--                            <hr class="divider" />-->
<!--                           Low-Level Vision />-->
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2022dada/DADA.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title"> Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution
                                    </h3>
                                    <p class="mb-2">Xiaoqian Xu, <b>Pengxu Wei*</b>, Weikai Chen, Yang Liu, Liang Lin and Guanbin Li</p>
                                    <p class="mb-2">CVPR (oral)  [<a href = "https://github.com/lonelyhope/DADA.git" target="_blank" >Project</a>,
                                        <a href = "assets/files/2022dada/DADA.pdf" target="_blank">Paper</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021mm/MM2021.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Robust Real-World Image Super-Resolution against Adversarial Attacks
                                    </h3>
                                    <p class="mb-2">Jiutao Yue, Haofeng Li, <b>Pengxu Wei*</b>, Guanbin Li and Liang Lin</p>
                                    <p class="mb-2">ACM Multimedia, 2021. [<a href = "assets/files/2021mm/MM2021.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021mm/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2020cdc/CDC.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Component Divide-and-Conquer for Real-World Image Super-Resolution</h3>
                                    <p class="mb-2"><b>Pengxu Wei</b>, Ziwei Xie, Hannan Lu, Zongyuan Zhan, Qixiang Ye, Wangmeng Zuo and Liang Lin</p>
                                    <p class="mb-2">ECCV, 2020. [<a href = "assets/files/2020cdc/Wei2020_CDC.pdf" target="_blank">Paper</a>,
                                        <a href = "https://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution" target="_blank" >Project</a>,
                                        <a href = "assets/files/2020cdc/bibtex.txt" target="_blank" >BibTex</a>]
                                    <!--<a href="assets/files/autoeval/Slides_CVPR_2021_AutoEvaluation.pdf" target="_blank">Slides</a>] -->
                                    </p>
<!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2020aim/AIM2020.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">AIM 2020 Challenge on Real Image Super-Resolution: Methods and Results
                                    </h3>
                                    <p class="mb-2"><b>Pengxu Wei*</b>, Hannan Lu, Radu Timofte, Liang Lin, Wangmeng Zuo, et al.</p>
                                    <p class="mb-2">ECCV workshop, 2020. [<a href = "assets/files/2020aim/Wei2020_Chapter_AIM2020ChallengeOnRealImageSup.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2020aim/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->


<!--                           High-Level Vision />-->
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021ijcv/IJCV2021.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Deep CockTail Networks: A Universal Framework for Visual Multi-source Domain Adaptation</h3>
<!--                                    <p class="mb-2"><b>Weijian Deng</b>, Liang Zheng, et al.</p> -->
                                    <p class="mb-2">Ziliang Chen, <b>Pengxu Wei*</b>, Jingyu Zhuang, Guanbin Li and Liang Lin</p>
                                    <p class="mb-2">IJCV, 2021. [<a href = "assets/files/2021ijcv/IJCV2021.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021ijcv/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021tnnls/figure.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Deductive Reinforcement Learning for Visual Autonomous Urban Driving Navigation
                                    </h3>
                                    <p class="mb-2">Changxin Huang, Ronghui Zhang, Meizi Ouyang, <b>Pengxu Wei*</b>, Junfan Lin, Jiang Su and Liang Lin</p>
                                    <p class="mb-2">IEEE TNNLS, 2021. [<a href = "assets/files/2021tnnls/Deductive_Reinforcement_Learning_for_Visual_Autonomous_Urban_Driving_Navigation.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021tnnls/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12" >
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021aaai/AAAI2021-figure.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras</h3>
                                    <p class="mb-2">Xipeng Chen, <b>Pengxu Wei*</b> and Liang Lin</p>
                                    <p class="mb-2">AAAI, 2021. [<a href = "assets/files/2021aaai/AAAI2021.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021aaai/bibtex.txt" target="_blank" >BibTex</a>]</p>
<!--                                    <p class="mb-2">(Journal version of <a href = "https://arxiv.org/abs/1812.00893" target="_blank">"Domain alignment with triplets"</a>)</p>-->
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2019pami/pami2019.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Min-Entropy Latent Model for Weakly Supervised Object Detection</h3>
                                    <p class="mb-2">Fang Wan, <b>Pengxu Wei</b>, Zhenjun Han, Jianbin Jiao and Qixiang Ye</p>
                                    <p class="mb-2">CVPR 2018 [<a href = "[CVPR]Min-Entropy Latent Model for Weakly Supervised Object Detection.pdf" target="_blank">Paper</a>]; IEEE T-PAMI, 2019 [<a href = "assets/files/2019pami/[2019PAMI]Min-Entropy Latent Model for Weakly Supervised Object Detection.pdf" target="_blank">Paper</a>,
                                        <a href = "https://github.com/WinFrand/MELM" target="_blank">Project</a>]</p>
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->

                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2019pami/pami2019.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">3D Human Pose Machines with Self-Supervised Learning</h3>
                                    <p class="mb-2">Keze Wang, Liang Lin, Chenhan Jiang, Chen Qian, <b>Pengxu Wei</b></p>
                                    <p class="mb-2">IEEE T-PAMI 2020 [<a href = "https://ieeexplore.ieee.org/document/8611195" target="_blank">Paper</a>]
                                        <a href = "assets/files/2020pose/bibtex.txt" target="_blank">BibTex</a>]</p>
                                    <!--                                    <p><a class="more-link" href="xxx" target="_blank"><i class="fas fa-external-link-alt"></i>Find out more</a></p>-->
                                </div><!--//desc-->
                            </div><!--//item-->


<!--                           Others />-->
                            <div class="item row">
                                <a class="col-md-4 col-12">
                                    <img class="img-fluid project-image rounded shadow-sm" src="assets/files/2021tnnls/figure.png" alt="project name" />
                                </a>
                                <div class="desc col-md-8 col-12">
                                    <h3 class="title">Graph-Convolved Factorization Machines for Personalized Recommendation
                                    </h3>
                                    <p class="mb-2">Yongsen Zheng, <b>Pengxu Wei*</b>, Ziliang Chen, Yang Cao and Liang Lin</p>
                                    <p class="mb-2">IEEE Transactions on Knowledge and Data Engineering (TKDE), 2021. [<a href = "assets/files/2021tkde/Graph-Convolved_Factorization_Machines_for_Personalized_Recommendation.pdf" target="_blank">Paper</a>,
                                        <a href = "assets/files/2021tnnls/bibtex.txt" target="_blank" >BibTex</a>]
                                    </p>
                                </div><!--//desc-->
                            </div><!--//item-->



                        </div><!--//content-->  
                    </div><!--//section-inner-->                
                </section><!--//section-->

                <section class="projects section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Selected Projects</h2>
                        <div class="content">

                            <div class="item">
                                <h3 class="title">A Near-Optimal Generative Learning Scheme for Neural Energy-Based Models</h3>
                                <p class="summary">Yang Wu, Xu cai, <b>Pengxu Wei</b>, Liang Lin.
<!--                                    <a href = "https://github.com/Simon4Yan/eSPGAN" target="_blank">Code</a>]-->
                                </p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title">Learning Causal Generative Model via Knowledge Consensus</h3>
                                <p class="summary">Yang Wu, <b>Pengxu Wei</b>, Yongyi Lu, Liang Lin</p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title">Real-World Image Super-Resolution Challenge (AIM 2020 in conjunction with ECCV 2020) [<a href = "https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank">AIM2020 webpage</a>]</h3>
                                <p class="summary">We provide high/low resolution image pairs of 3 scales captured by 5 different DSLR cameras through zooming lens. The challenging contains 3 tracks, one track per scale. The detail of the dataset is provided in Table 1. For the convergence of training, images in the trainset are cropped into fixed size patches using sliding window after careful alignment for image pairs. [<a href = "https://competitions.codalab.org/competitions/24680" target="_blank">Chanllenge Page</a>] </p>
                                <p>
                                    <b>Organizers</b>: Pengxu Wei (Sun Yat-Sen University), Hannan Lu (Harbin Institute of Technology), Wangmeng Zuo (Harbin Institute of Technology), Radu Timofte (ETH Zurich)
                                </p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title">IEEE CASS Seasonal School on New Trends of Visual and Language Understanding (NT-VLU) [<a href = "http://ieeecass.sysuhcp.com/" target="_blank">Website</a>, <a href = "https://live.bilibili.com/23453433" target="_blank">Video</a>]</h3>
                                <p class="summary">To organize the IEEE CASS Seasonal School on NT-VLU, we invited several top-tier researchers to present their works and arrange two panels to discuss the new trends of NT-VLU. This seasonal school aimed to promote the frontier of language and vision research and to provide an ambiance for fruitful exchange of ideas and discussion of advances, challenges, and trends of this area in the near future. [<a href = "http://ieeecass.sysuhcp.com/" target="_blank">Chanllenge Page</a>] </p>
                                <p>
                                    <b>Spearkers</b>: Jiebo Luo (University of Rochester), Cees G.M. Snoek (University of Amsterdam), Wen-Huang Cheng (National Yang Ming Chiao Tung University), Hanwang Zhang (Nanyang Technological University), Michael Kampffmeyer (UiT the Arctic University of Norway), Dan Xu (Hong Kong University of Sciences and Technology), Pengfei Liu (Carnegie Mellon University)
                                </p>
                                <p>
                                    <b>Organizers</b>: Liang Lin(Sun Yat-Sen University), Wangmeng Zuo (Harbin Institute of Technology), Xiaodan Liang(Sun Yat-Sen University), Yunchao Wei (Beijing Jiaotong University), Pengxu Wei (Sun Yat-Sen University), Guanbin Li(Sun Yat-Sen University)
                                </p>
                            </div><!--//item-->

                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->


            </div><!--//primary-->


            <div class="secondary col-lg-4 col-12">
                 <aside class="info aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading sr-only">Basic Information</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li><i class="fas fa-map-marker-alt"></i><span class="sr-only">Location:</span>Guangzhou, China</li>
<!--                                <li><i class="fas fa-file"></i><span class="sr-only">Curriculum Vitae:</span><a href="assets/files/DENG-WEIJIAN-CV.pdf" target="_blank">Curriculum Vitae</a></li> -->
                                <li><i class="fas fa-envelope"></i><span class="sr-only">Email:</span><a href="#">weipx3@mail.sysu.edu.cn</a></li>

                            </ul>
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//aside-->

                
                <aside class="testimonials aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Recent Focus</h2>
                        <div class="content">
                            <div class="item">
                                <blockquote class="quote">                                  
                                    <p><i class="fas fa-quote-left"></i> Towards Transferable, Robust and Reliable Model Learning</p>
                                </blockquote>                
                            </div><!--//item-->
                            
                            
<!--                             <p><a class="more-link" href="https://simon4yan.github.io/AutoEval/"target="_blank"><i class="fas fa-external-link-alt"></i>Our recent work</a></p>-->
                            
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->




                <aside class="credits aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Professional Service</h2>
                        <div class="content">
                            <ul class="list-unstyled pb-2">
                                <li><b>Reviewer</b>: CVPR; ICCV; ECCV; IJCAI; AAAI; IEEE-TPAMI; IEEE-TIP; IEEE-TCSVT, CVIU</li>
                                <li><b>Co-organizer</b>: IEEE CASS Seasonal School 2021 on <a href = "http://ieeecass.sysuhcp.com/" target="_blank">"New Trends of Visual and Language Understanding"</a>; ECCV 2020 workshop on <a href = "http://ai.bu.edu/visda-2020" target="_blank"> AIM 2020 "Real-World Image Super-Resolution Challenge"</a></li>
<!--                                <li><b>Guest speaker</b>: SUTD 2018/12 (image-image translation); ANU 2019/09 (SVDNet) </li> -->
                                <li> </li>
                            </ul>

                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->

<!--                <aside class="credits aside section">-->
<!--                    <div class="section-inner shadow-sm rounded">-->
<!--                        <h2 class="heading">Friends</h2>-->
<!--                        <div class="content">-->
<!--                            <ul class="list-unstyled pb-2">-->
<!--                                <li><a href = "https://xiaoxiaosun.com/" target="_blank">Xiaoxiao Sun </a> </li>-->
<!--                                <li><a href = " https://yifansun-reid.github.io/" target="_blank"> Yifan Sun</a> </li>-->
<!--                                <li><a href = "https://scholar.google.com/citations?user=bRKA7fUAAAAJ&hl=en " target="_blank">Gangming Zhao </a> </li>-->
<!--                                <li><a href = "https://fangweizhong.xyz/ " target="_blank">Fangwei Zhong </a> </li>-->
<!--                                <li><a href = "https://github.com/ZhaoShengjian " target="_blank">Shengjian Zhao </a> </li>-->
<!--                            </ul>-->

<!--                        </div>&lt;!&ndash;//content&ndash;&gt;-->
<!--                    </div>&lt;!&ndash;//section-inner&ndash;&gt;-->
<!--                </aside>&lt;!&ndash;//section&ndash;&gt;-->
                <script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=5x16sh9ozi2&amp;m=7&amp;c=baff00&amp;cr1=ff0000&amp;sx=0" async="async"></script>

              
            </div><!--//secondary-->    
        </div><!--//row-->
    </div><!--//masonry-->
    
    <!-- ******FOOTER****** --> 
    <footer class="footer">
        <div class="container text-center">
                <!--/* This template is free as long as you keep the attribution link below. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
                <small class="copyright">Designed with <i class="fas fa-heart"></i> by <a href="https://themes.3rdwavemedia.com" target="_blank">Xiaoying Riley</a> for developers</small>
        </div><!--//container-->
    </footer><!--//footer-->
 
    <!-- Javascript -->          
    <script type="text/javascript" src="assets/plugins/jquery-3.4.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/popper.min.js"></script> 
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>    
    <script type="text/javascript" src="assets/plugins/jquery-rss/dist/jquery.rss.min.js"></script> 
    <!-- github calendar plugin -->
    <script type="text/javascript" src="assets/plugins/github-calendar/dist/github-calendar.min.js"></script>
    <!-- github activity plugin -->
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mustache.js/0.7.2/mustache.min.js"></script>
    <script type="text/javascript" src="assets/plugins/github-activity/github-activity-0.1.5.min.js"></script>
    <!-- custom js -->
    <script type="text/javascript" src="assets/js/main.js"></script>            
</body>
</html> 

